{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "generate_results.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PeYZFcZfqDm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Installing libraries\n",
        "!pip install transformers\n",
        "!pip install  nlp\n",
        "!pip install pyarrow==0.16.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPJrfdXsatFu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import nlp\n",
        "from tqdm import tqdm\n",
        "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EgLgEVkfra5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Befere running evaluation we have to convert tensorflow checkpoint into pytorch model.\n",
        "#See here: https://github.com/huggingface/transformers/blob/master/src/transformers/convert_t5_original_tf_checkpoint_to_pytorch.py\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XiwYcFffszU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Import the tokenizer and the config file from drive\n",
        "#The config file can be download from this link: https://s3.amazonaws.com/models.huggingface.co/bert/t5-small-config.json\n",
        "\n",
        "config = T5Config.from_json_file('/content/drive/My Drive/conf/finetuned_model_2M/config.json')\n",
        "tokenizer = T5Tokenizer.from_pretrained('/content/drive/My Drive/conf/finetuned_model_2M/dl4se_vocab.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqYdPg2Rfuhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Change the prefix when want to evaluate different tasks\n",
        "# (1) generate small patch\n",
        "# (2) generate medium patch\n",
        "# (3) generate abt assert\n",
        "# (4) generate raw assert\n",
        "\n",
        "# If you're evaluating abt/raw assert generative tasks, change example['method'].lower() for the input_text and  example['assertion'].lower() for the target_text\n",
        "\n",
        "def add_eos_to_examples(example):\n",
        "    example['input_text'] = 'generate abt assert: %s </s>' % example['method'].lower()\n",
        "    example['target_text'] = '%s </s>' % example['assertion'].lower()\n",
        "    return example\n",
        "\n",
        "\n",
        "def convert_to_features(example_batch):\n",
        "    input_encodings = tokenizer.batch_encode_plus(example_batch['input_text'], pad_to_max_length=True, max_length=512)\n",
        "    target_encodings = tokenizer.batch_encode_plus(example_batch['target_text'], pad_to_max_length=True, max_length=512)\n",
        "\n",
        "    encodings = {\n",
        "        'input_ids': input_encodings['input_ids'], \n",
        "        'attention_mask': input_encodings['attention_mask'],\n",
        "        'target_ids': target_encodings['input_ids'],\n",
        "        'target_attention_mask': target_encodings['attention_mask']\n",
        "    }\n",
        "\n",
        "    return encodings"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q360jPaLfxMx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "# Here we have to change the script for loading the dataset\n",
        "# Pick the script according to the task and load it on this colab instance\n",
        "# Make sure to load the test set as well; otherwise, it doesn't work.\n",
        "\n",
        "valid_dataset = nlp.load_dataset('/content/assertion_dataset_script.py', split=nlp.Split.TEST)\n",
        "\n",
        "\n",
        "# map add_eos_to_examples function to the dataset example wise \n",
        "valid_dataset = valid_dataset.map(add_eos_to_examples, load_from_cache_file=False)\n",
        "\n",
        "# map convert_to_features batch wise\n",
        "valid_dataset = valid_dataset.map(convert_to_features, batched=True, load_from_cache_file=False)\n",
        "\n",
        "\n",
        "columns = ['input_ids', 'target_ids', 'attention_mask','target_attention_mask']\n",
        "valid_dataset.set_format(type='torch', columns=columns)\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E6Vgfly4f0JB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#The BATCH_SIZE must be set according to the available VRAM.\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "dataloader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9incoTgAwZ7_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "efabef53-7355-4be9-ac01-ad234dfebe97"
      },
      "source": [
        "#Let's import the ground truth from the test dataset\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('test.tsv',header=None,sep='\\t')\n",
        "\n",
        "references=[]\n",
        "\n",
        "for item in df[1]:\n",
        "  references.append(item.lower())\n",
        "\n",
        "references[1]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'org . junit . assert . assertequals ( expected , buf )'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPA2aw6egEgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Set CUDA device to leverage GPU computation\n",
        "CUDA = torch.device(\"cuda\")\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(\n",
        "        '/content/drive/My Drive/conf/finetuned_model_2M/model.bin',\n",
        "        config=config\n",
        "        ).to(CUDA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7KQ94kR2gJFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "80e9d325-3fcb-4b05-93f3-8fb3b885d058"
      },
      "source": [
        "# Change the max_length in model.generate according to specific tasks\n",
        "# For bfp_small and bfp_medium we set respectively 128 and 256.\n",
        "# For both abt assert and raw assert tasks, we used 512 as max length\n",
        "\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "predictions = []\n",
        "\n",
        "BEAM_SIZE = 10\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "for batch in tqdm(dataloader):\n",
        "\n",
        "      outs = model.generate(\n",
        "                          input_ids=batch['input_ids'].to(CUDA),\n",
        "                          attention_mask=batch['attention_mask'].to(CUDA),\n",
        "                          num_beams=BEAM_SIZE, \n",
        "                          max_length=512,\n",
        "                          num_return_sequences=BEAM_SIZE, \n",
        "                          early_stopping=True\n",
        "                          )\n",
        "    \n",
        "\n",
        "    \n",
        "      outs = [tokenizer.decode(ids, skip_special_tokens=True)  for ids in outs]\n",
        "      predictions.extend(outs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  9%|â–Š         | 170/1977 [05:14<53:47,  1.79s/it]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLKmlAJJO1M9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "87f5f261-d6e5-4c06-814d-97da9889f22d"
      },
      "source": [
        "pred_refined = []\n",
        "for pred in predictions:\n",
        "    if len(pred)>=2:\n",
        "      if pred[0]=='\"':\n",
        "          pred = pred[1:]\n",
        "      if pred[-1]=='\"':\n",
        "          pred = pred[:-1]\n",
        "    pred_refined.append(pred)\n",
        "    \n",
        "len(pred_refined),len(predictions)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(79050, 79050)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhskxiWlgA2W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "counter_pred = 0\n",
        "\n",
        "mispred_list = []\n",
        "\n",
        "sanity_check_list = []\n",
        "\n",
        "idx = 0\n",
        "\n",
        "len_prediction=(len(pred_refined))\n",
        "\n",
        "for i in range(0, len_prediction, BEAM_SIZE):\n",
        "\n",
        "    items_to_analyze = pred_refined[i:i+BEAM_SIZE]\n",
        "    target_item = ''.join(references[idx].split(' '))\n",
        "    \n",
        "\n",
        "    for pred in items_to_analyze:\n",
        "        pred_ref = ''.join(pred.split(' '))\n",
        "        if pred_ref == target_item:\n",
        "            counter_pred+=1\n",
        "            sanity_check_list.append(pred_ref)\n",
        "            break\n",
        "        else:\n",
        "          mispred_list.append(pred)\n",
        "         \n",
        "          \n",
        "        \n",
        "    idx += 1\n",
        "\n",
        "print('% of perfect predictions: ',(counter_pred/len(references))*100 )\n",
        "print(counter_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDm8vAvCgOCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#SAVING RESULTS\n",
        "\n",
        "idx=0\n",
        "\n",
        "with open('/content/drive/My Drive/conf/results_final/assert/abt/predictions_5/mispredictions_5.txt', 'w') as f:\n",
        "    for i in range( 0, len(mispred_list), BEAM_SIZE):\n",
        "        \n",
        "        items_to_analyze = mispred_list[i:i+BEAM_SIZE]\n",
        "\n",
        "        f.write('\\n************\\n')\n",
        "        f.write(\"tgt: %s\\n\" % references[idx])\n",
        "        for (index,mispred) in enumerate(items_to_analyze):\n",
        "          f.write('[%s]: %s\\n' % (str(index),mispred) )\n",
        "        f.write('\\n************\\n')\n",
        "\n",
        "        idx+=1"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls8LiUpVgRqo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('/content/drive/My Drive/conf/results_final/assert/abt/predictions_5/predictions_5.txt', 'w') as f:\n",
        "    for item in pred_refined:\n",
        "        f.write(\"%s\\n\" % item)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLOxaqzJdQtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}