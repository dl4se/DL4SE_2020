{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### In this notebook we're going to compute the overlap metrics between T5 and the baselines ######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[T5] % of perfect predictions: 11.441237294847538 10401/90908\n",
      "[Baseline] % of perfect predictions: 3.3528402340828087 3048/90908\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "counter_pred = 0\n",
    "\n",
    "mispred_list = []\n",
    "\n",
    "sanity_check_list = []\n",
    "\n",
    "idx = 0\n",
    "\n",
    "BEAM_SIZE = 1\n",
    "\n",
    "\n",
    "### LOAD REFERENCES AND T5 PREDICTIONS ####\n",
    "\n",
    "#Let's import the ground truth from the test dataset\n",
    "df = pd.read_csv('/Users/antonio/Desktop/T5_project/datasets/fine-tuning/CS/test.tsv',header=None,sep='\\t')\n",
    "\n",
    "references=[]\n",
    "\n",
    "for item in df[1]:\n",
    "    references.append(item.lower())\n",
    "\n",
    "\n",
    "perfect_pred_t5 = []\n",
    "pred_refined_t5=[]\n",
    "pred_refined_t5_to_set = []\n",
    "\n",
    "with open('/Users/antonio/Desktop/ICSE_PRED/T5/CS_predictions@1.txt') as fread:\n",
    "    for item in fread.readlines():\n",
    "        item = item.strip()\n",
    "        if len(item)>=2:\n",
    "          if item[0]=='\"':\n",
    "              item = item[1:]\n",
    "          if item[-1]=='\"':\n",
    "              item = item[:-1]\n",
    "                \n",
    "        pred_refined_t5.append(item)\n",
    "        \n",
    "    \n",
    "len_prediction=(len(pred_refined_t5))\n",
    "\n",
    "\n",
    "def cleanCommentCSTask(comment):\n",
    "    comment = comment[0]\n",
    "    target_comment = re.findall(\"<s>([\\s\\S]*?)</s>\", comment)\n",
    "    if len(target_comment)>0: return target_comment[0].strip().lower()\n",
    "    else: return ''\n",
    "\n",
    "for i in range(0, len_prediction, BEAM_SIZE):\n",
    "\n",
    "    items_to_analyze = pred_refined_t5[i:i+BEAM_SIZE]\n",
    "    target_item = ''.join(references[idx].split(' '))\n",
    "    \n",
    "\n",
    "    for pred in items_to_analyze:\n",
    "        pred_ref = ''.join(pred.split(' '))\n",
    "        if pred_ref == target_item:\n",
    "            perfect_pred_t5.append(items_to_analyze)\n",
    "            counter_pred+=1\n",
    "            sanity_check_list.append(pred_ref)\n",
    "            pred_refined_t5_to_set.append(pred_ref)\n",
    "            break\n",
    "       \n",
    "        \n",
    "    idx += 1\n",
    "\n",
    "percentage = (counter_pred/len(references))*100 \n",
    "print('[T5] % of perfect predictions: {} {}/{}'.format(percentage, counter_pred, len(references)))\n",
    "\n",
    "\n",
    "with open('CS_perfect@1.txt','a+') as fwrite:\n",
    "    for pred in perfect_pred_t5:\n",
    "        fwrite.write(pred[0]+'\\n')\n",
    "\n",
    "\n",
    "############# BASELINE ##########\n",
    "\n",
    "counter_pred = 0\n",
    "\n",
    "mispred_list = []\n",
    "\n",
    "sanity_check_list = []\n",
    "\n",
    "idx = 0\n",
    "\n",
    "pred_refined_baseline=[]\n",
    "pred_refined_baseline_to_set = []\n",
    "\n",
    "with open('/Users/antonio/Desktop/ICSE_PRED/Baselines/CS/predictions.txt') as fread:\n",
    "    for item in fread.readlines():\n",
    "        item = item.strip().lower()\n",
    "        pred_refined_baseline.append(item)\n",
    "        \n",
    "\n",
    "### UNCOMMENT ONLY FOR BFmedium since the Test dataset is not in the same order(row-wise) of the original one ######\n",
    "# references=[]\n",
    "\n",
    "# with open('/Users/antonio/Downloads/fixed.txt') as fread:\n",
    "#     for item in fread.readlines():\n",
    "#         references.append(item.strip().lower())\n",
    "        \n",
    "    \n",
    "for i in range(0, len_prediction, BEAM_SIZE):\n",
    "    \n",
    "    #### Instrumentation for CS task ####\n",
    "    #### Keep COMMENTED ####\n",
    "    \n",
    "#     if len(pred_refined_baseline[i:i+BEAM_SIZE])==0:\n",
    "#         continue\n",
    "#     else:  \n",
    "#         items_to_analyze = [cleanCommentCSTask(pred_refined_baseline[i:i+BEAM_SIZE])]\n",
    "    \n",
    "    items_to_analyze = pred_refined_t5[i:i+BEAM_SIZE]\n",
    "    target_item = ''.join(references[idx].split(' '))\n",
    "    \n",
    "\n",
    "    for pred in items_to_analyze:\n",
    "        pred_ref = ''.join(pred.split(' '))\n",
    "        if pred_ref == target_item:\n",
    "            counter_pred+=1\n",
    "            sanity_check_list.append(pred_ref)\n",
    "            pred_refined_baseline_to_set.append(pred_ref)\n",
    "            break\n",
    "       \n",
    "        \n",
    "    idx += 1\n",
    "\n",
    "percentage = (counter_pred/len(references))*100 \n",
    "print('[Baseline] % of perfect predictions: {} {}/{}'.format(percentage, counter_pred, len(references)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared:  4.966329966329966\n",
      "Only T5:  93.46801346801347\n",
      "Only BASELINE:  1.5656565656565657\n"
     ]
    }
   ],
   "source": [
    "###### OVERLAP #####\n",
    "\n",
    "set_t5 = set(pred_refined_t5_to_set)\n",
    "set_baseline = set(pred_refined_baseline_to_set)\n",
    "\n",
    "#### SHARED #####\n",
    "intersection = set_t5.intersection(set_baseline)\n",
    "union = set_t5.union(set_baseline)\n",
    "shared = (len(intersection)/len(union) ) * 100\n",
    "\n",
    "print('Shared: ',shared)\n",
    "# print(len(intersection))\n",
    "\n",
    "#### ONLY T5 #####\n",
    "difference = set_t5.difference(set_baseline)\n",
    "union = set_t5.union(set_baseline)\n",
    "t5_only = (len(difference)/len(union) ) * 100\n",
    "\n",
    "print('Only T5: ',t5_only)\n",
    "# print(len(intersection))\n",
    "\n",
    "#### ONLY BASELINE #####\n",
    "difference = set_baseline.difference(set_t5)\n",
    "union = set_t5.union(set_baseline)\n",
    "baseline_only = (len(difference)/len(union) ) * 100\n",
    "\n",
    "print('Only BASELINE: ',baseline_only)\n",
    "\n",
    "assert(t5_only + shared + baseline_only > 99.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
