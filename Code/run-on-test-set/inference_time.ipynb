{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "inference_time.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "4bPWxwacrDNO",
        "colab": {}
      },
      "source": [
        "#Installing libraries\n",
        "!pip install transformers\n",
        "!pip install  nlp\n",
        "!pip install pyarrow==0.16.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uALF__AnrKDt",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import nlp\n",
        "from transformers import T5Tokenizer, T5Config, T5ForConditionalGeneration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "seKW8xqVrKd3",
        "colab": {}
      },
      "source": [
        "config = T5Config.from_json_file('config.json')\n",
        "tokenizer = T5Tokenizer.from_pretrained('model.ckpt.model')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Du6ox3aVrKgX",
        "colab": {}
      },
      "source": [
        "model = T5ForConditionalGeneration.from_pretrained('small_model.bin',config=config)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mL2-lu5wrKi-",
        "colab": {}
      },
      "source": [
        "#Let's import the ground truth\n",
        "import pandas as pd\n",
        "import time\n",
        "from random import sample\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "SAMPLE_SIZE = 10\n",
        "\n",
        "df = pd.read_csv('test_comment.tsv',header=None,sep='\\t')\n",
        "\n",
        "\n",
        "inputs = []\n",
        "\n",
        "for item in df[0]:\n",
        "    inputs.append('generate comment: %s' % item)\n",
        "\n",
        "\n",
        "\n",
        "samp = sample(inputs,SAMPLE_SIZE)\n",
        "\n",
        "items = [tokenizer.encode(item,return_tensors='pt') for item in samp]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoZLk162ipwX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eynvXbcGrKlm",
        "colab": {}
      },
      "source": [
        "BEAM_SIZE = [1,5,10,25,50]\n",
        "\n",
        "with open('INF_TIME_comment.txt','w') as fwrite:\n",
        "\n",
        "\n",
        "    for beam in tqdm(BEAM_SIZE):\n",
        "\n",
        "        acc=0\n",
        "\n",
        "        for idx in range(0,SAMPLE_SIZE):\n",
        "\n",
        "                start = time.time()\n",
        "\n",
        "                beam_output = model.generate(\n",
        "                  items[idx],\n",
        "                  max_length=512, \n",
        "                  num_beams=beam, \n",
        "                  early_stopping=True\n",
        "                )\n",
        "\n",
        "                end = time.time()\n",
        "\n",
        "                acc += (end-start)\n",
        "\n",
        "        fwrite.write('Average inference time on beam width k=%s: %s\\n' % (beam,str(acc/SAMPLE_SIZE)))\n",
        "    \n",
        "    fwrite.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ew_sOU69rKn2",
        "colab": {}
      },
      "source": [
        "with open('inference_samples.txt','w') as writeSam:\n",
        "    for item in samp:\n",
        "        writeSam.write(item+'\\n')\n",
        "    writeSam.close()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aYjA4dkvrKqL",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1rQSVa_crKsv",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}